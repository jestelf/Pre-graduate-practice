# Модуль подтверждения безопасного голосового подключения

## Описание проекта  
Данный репозиторий содержит реализацию **модуля подтверждения безопасного подключения** пользователей к корпоративной информационной системе с автоматической детекцией синтетической (deepfake) речи. Модуль анализирует короткий аудиофрагмент (3–5 с) и решает, является ли голос реальным или сгенерированным при помощи TTS/клонирования. При обнаружении подделки доступ блокируется, а инцидент фиксируется в системе безопасности.

---

## Содержание

- [Особенности](#особенности)  
- [Требования](#требования)  
- [Установка](#установка)  
- [Использование](#использование)  
- [Архитектура](#архитектура)  
- [Данные и подготовка](#данные-и-подготовка)  
- [Обучение модели](#обучение-модели)  
- [Оценка качества](#оценка-качества)  
- [Развёртывание](#развёртывание)  
- [Конфигурация и параметры](#конфигурация-и-параметры)  
- [Логирование и мониторинг](#логирование-и-мониторинг)  
- [Планы по развитию](#планы-по-развитию)  
- [Авторы и контакты](#авторы-и-контакты)  
- [Лицензия](#лицензия)  
- [Ссылки и источники](#ссылки-и-источники)  

---

## Особенности

- **Бинарная классификация**: «реальный голос» vs «синтетический голос»  
- Время обработки одного фрагмента ≤ 300 мс (на CPU ≤ 0.2 с; на GPU ≈ 30 мс)  
- **API**: REST-сервис на Flask (`/verify_voice`)  
- **Модульная архитектура**: предобработка, CNN+Transformer, DecisionLogic, API, логирование  
- Настраиваемый порог детекции (по умолчанию 0.5)  
- Масштабируемость: поддержка многопоточного режима или кластеризации (Docker/Kubernetes)  

---

## Требования

- Python ≥ 3.8  
- PyTorch ≥ 1.13  
- torchaudio, librosa  
- Flask  
- (опционально) GPU с CUDA для ускоренного инференса  
- Linux (Ubuntu 20.04+) или Windows Server  

---

## Установка

1. Клонировать репозиторий:
   ```bash
   git clone https://github.com/ВашаОрганизация/secure-voice-auth.git
   cd secure-voice-auth
````

2. Создать виртуальное окружение и установить зависимости:

   ```bash
   python3 -m venv venv
   source venv/bin/activate   # или venv\Scripts\activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
3. Разместить файл модели `model.pth` в папке `models/` (см. раздел [Обучение модели](#обучение-модели)).

---

## Использование

Запустить сервис:

```bash
export FLASK_APP=app.py
flask run --host=0.0.0.0 --port=5000
```

Пример запроса:

```bash
curl -X POST http://localhost:5000/verify_voice \
     -H "Content-Type: audio/wav" \
     --data-binary @test.wav
```

Пример ответа:

```json
{
  "is_fake": false,
  "confidence": 0.12
}
```

* `is_fake`: `true` — синтетический голос; `false` — настоящий
* `confidence`: вероятность синтетичности (0…1)

---

## Архитектура

1. **AudioPreprocessor**

   * Загрузка WAV (16 kHz, 16-bit PCM)
   * Обрезка/дополнение до 3 с, детекция и удаление тишины
   * Преобразование в мел-спектрограмму (80 Mel-коэффициентов, окно 25 ms, шаг 10 ms)
2. **DeepFakeDetectorModel**

   * **CNN-блок**: 2× Conv2D → ReLU → BatchNorm → MaxPool
   * **Патчи**: разбиение выходных карт векторов на фрагменты 4×4 → позиционное кодирование
   * **TransformerEncoder**: 4 слоя, d\_model=256, 4 heads
   * **Pooling**: Global Average → эмбеддинг 256
   * **ClassificationHead**: Linear → сигмоида
3. **DecisionLogic**

   * Применяет порог `P_thr` к выходной вероятности
   * Обрабатывает ошибки форматов и шумных аудио
4. **API (Flask)**

   * Эндпойнт `/verify_voice`
   * Аутентификация через API-ключ (в HTTP-заголовке)
5. **Logging & Monitoring**

   * Запись результатов: время, user\_id, результат, confidence
   * Отправка тревог в SIEM/Kafka
   * Heartbeat для системы мониторинга

---

## Данные и подготовка

* Собран датасет \~2 100 файлов (3 класса: `real`, `synth_same_text`, `synth_random_text`), сбалансирован
* Разбиение: train/val/test ≈ 60%/20%/20%
* Аугментации: добавление белого и офисного шума (SNR 20/10 dB) к 10% данных
* Преобработка описана в `data/preprocessor.py`

---

## Обучение модели

```bash
python train.py \
  --data-dir data/ \
  --epochs 10 \
  --batch-size 4 \
  --lr 1e-4 \
  --save-dir models/
```

* Оптимизатор: Adam (lr=1e-4)
* Функция потерь: `BCEWithLogitsLoss`
* Мониторинг: accuracy, precision, recall, F1 на валидации
* Лучшая модель (по F1) сохраняется автоматически

---

## Оценка качества

| Метрика   | Train | Val  | Test |
| --------- | ----- | ---- | ---- |
| Accuracy  | 0.92  | 0.86 | 0.88 |
| Precision | 0.90  | 0.84 | 0.85 |
| Recall    | 0.93  | 0.88 | 0.89 |
| F1-score  | 0.91  | 0.86 | 0.87 |

*Тестовые результаты получены на GPU NVIDIA RTX 3060.*

---

## Развёртывание

Рекомендуется контейнеризация:

```Dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY . .
RUN pip install --no-cache-dir -r requirements.txt
EXPOSE 5000
CMD ["flask", "run", "--host=0.0.0.0", "--port=5000"]
```

* Сборка: `docker build -t secure-voice-auth .`
* Запуск: `docker run -d -p 5000:5000 secure-voice-auth`
* Для масштабирования используйте Kubernetes с авто-скейлингом по CPU/GPU.

---

## Конфигурация и параметры

* `config.yaml` содержит:

  * `model_path`: путь к файлу весов
  * `sample_rate`: 16000
  * `duration`: 3
  * `mel_n_mels`: 80
  * `threshold`: 0.5
  * API-ключи и параметры логирования

---

## Логирование и мониторинг

* Логи в формате JSON (`logs/app.log`)
* Интеграция с SIEM/Kafka (настройки в `monitoring/`)
* Heartbeat эндпойнт `/health` возвращает `{"status":"ok"}`

---

## Планы по развитию

* Поддержка мультиклассовой классификации (различение типов дипфейков)
* Онлайн-дообучение на новых примерах
* Расширение на другие языки
* Оптимизация модели (квантование, TensorRT)

---

## Авторы и контакты

* **Ширшов А. А.** (студент-практикант)
* **ООО «Компания-разработчик»**, служба ИБ
* Научный руководитель: к.д.н. Коротков Дмитрий Павлович

---

## Лицензия

MIT License © 2025

---

## Ссылки и источники

1. ГОСТ 34.602-2020 – Техническое задание на АС
2. ASVspoof 2019, WaveFake, LibriSpeech
3. Zhang B. et al., 2025 – Обзор методов детекции audio-deepfake
4. Tan J. H., 2023 – Практика применения anti-deepfake в ИБ
and more...

